/* This file is part of SableCC ( http://sablecc.org ).
 *
 * See the NOTICE file distributed with this work for copyright information.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

Package org.sablecc.sablecc.syntax3;

Helpers

  // Based on Unicode 5.1.0

  ascii_lu = [0x0041 .. 0x005A];
  ascii_ll = [0x0061 .. 0x007A];

  ascii_l = [ascii_lu + ascii_ll];

  ascii_nd = [0x0030 .. 0x0039];

  ascii_n = ascii_nd;

  ascii_pc = 0x005F;
  ascii_pd = 0x002D;
  ascii_ps = [[0x0028 + 0x005B] + 0x007B];
  ascii_pe = [[0x0029 + 0x005D] + 0x007D];
  ascii_po = [[[[0x0021 .. 0x0023] + [0x0025 .. 0x0027]] +
               [[0x002A + 0x002C] + [0x002E .. 0x002F]]] +
              [[[0x003A .. 0x003B] + [0x003F .. 0x0040]] + 0x005C]];

  ascii_p = [[[ascii_pc + ascii_pd] + [ascii_ps + ascii_pe]] + ascii_po];

  ascii_sm = [[0x002B + [0x003C .. 0x003E]] + [0x007C + 0x007E]];
  ascii_sc = 0x0024;
  ascii_sk = [0x005E + 0x0060];

  ascii_s = [[ascii_sm + ascii_sc] + ascii_sk];

  ascii_zs = 0x0020;

  ascii_z = ascii_zs;

  ascii_cc = [[0x0000 .. 0x001F] + 0x007F];

  ascii_c = ascii_cc;

  ascii = [[[ascii_l + ascii_n] + [ascii_p + ascii_s]] + [ascii_z + ascii_c]];

  ascii_pattern_white_space = [[0x0009 .. 0x000D] + 0x0020];
  ascii_pattern_syntax = [[[[0x0021 .. 0x002F] + [0x003A .. 0x0040]] +
                          [[0x005B .. 0x005E] + 0x0060]] + [0x007B .. 0x007E]];

  ascii_id_start = [[0x0041 .. 0x005A] + [0x0061 .. 0x007A]];
  ascii_id_continue = [[[0x0030 .. 0x0039] + [0x0041 .. 0x005A]] +
                       [0x005F + [0x0061 .. 0x007A]]];

  ascii_identifier = ascii_id_start ascii_id_continue*;

  ascii_newline = [0x000A .. 0x000D] | 0x000D 0x000A;

  // Other helpers

  single_char = [[[ascii - ascii_c] + ascii_pattern_white_space] -
                 [[0x000A .. 0x000D] + [''' + '\']]];
  char_escape = '\' [''' + '\'];

  line_comment_char = [[[ascii - ascii_c] + ascii_pattern_white_space] -
                       [[0x000A .. 0x000D] + '\']];
  line_comment_escape = '\' '\';

  long_comment_char = [[[ascii - ascii_c] + ascii_pattern_white_space] -
                       [['*' + '/'] + '\']];
  long_comment_escape = '\' ['*' + '\'];

  decimal_digit = ['0' .. '9'];
  hexadecimal_digit = [decimal_digit + [['A' .. 'F'] + ['a' .. 'f']]];

  sign = ['+' + '-'];
  x = ['X' + 'x'];

Tokens

  alternative_keyword = '$alternative';
  and_keyword = '$and';
  any_keyword = '$any';
  context_keyword = '$context';
  dangling_keyword = '$dangling';
  diff_keyword = '$diff';
  end_keyword = '$end';
  group_keyword = '$group';
  ignored_keyword = '$ignored';
  inlined_keyword = '$inlined';
  investigator_keyword = '$investigator';
  language_keyword = '$language';
  left_keyword = '$left';
  lexer_keyword = '$lexer';
  longest_keyword = '$longest';
  look_keyword = '$look';
  not_keyword = '$not';
  new_keyword = '$new';
  null_keyword = '$null';
  parser_keyword = '$parser';
  priority_keyword = '$priority';
  production_keyword = '$production';
  rejected_keyword = '$rejected';
  right_keyword = '$right';
  separator_keyword = '$separator';
  shortest_keyword = '$shortest';
  start_keyword = '$start';
  start_no_end_keyword = '$start_no_end';
  token_keyword = '$token';
  transformation_keyword = '$transformation';
  tree_keyword = '$tree';

  identifier = ascii_identifier;

  alternative_name = '{' ascii_identifier ':}';
  element_name = '[' ascii_identifier ':]';

  epsilon = ''' ''';
  char = ''' (single_char | char_escape) ''';
  string = ''' (single_char | char_escape)+ ''';
  number = decimal_digit+;

  dec_char = '#' sign? decimal_digit+;
  hex_char = '#' x sign? hexadecimal_digit+;

  l_par = '(';
  r_par =')';

  assign = '=';
  arrow = '->';
  bar = '|';
  caret = '^';
  colon = ':';
  comma = ',';
  dot = '.';
  gt = '>';
  minus = '-';
  plus = '+';
  q_mark = '?';
  semicolon = ';';
  star = '*';
  three_dots = '...';
  two_dots = '..';

  blank = ascii_pattern_white_space+;

  line_comment = '//' (line_comment_char | line_comment_escape)*
                 ascii_newline?;

  long_comment = '/*' ([long_comment_char + '/'] | long_comment_escape)*
                 ('*' ((long_comment_char | long_comment_escape)
                       ([long_comment_char + '/'] | long_comment_escape)*)?)*
                 '*/';

  ctrl_z = 0x001A;

  invalid_keyword = '$' ascii_identifier;
  invalid_number = decimal_digit+ ascii_identifier;
  invalid_string = ''' (single_char | char_escape)*;
  invalid_dec_char = '#' sign? decimal_digit+ ascii_identifier;
  invalid_hex_char = '#' x sign? hexadecimal_digit+ ascii_identifier;

Ignored Tokens

  blank, line_comment, long_comment;

Productions

  grammar
    =
      language_name lexer? parser transformation? tree? ctrl_z?
        {-> New grammar(language_name.language_keyword, language_name.identifier, lexer, parser, transformation, tree) }
    ;

  language_name
        {-> language_keyword identifier }
    =
      language_keyword identifier semicolon
        {-> language_keyword identifier }
    ;

  lexer
    =
      lexer_keyword [named_expressions]:named_expression* [groups]:group* lexer_contexts lexer_investigators
        {-> New lexer(lexer_keyword, [named_expressions], [groups], [lexer_contexts.lexer_contexts], [lexer_investigators.lexer_investigators]) }
    ;

  named_expression
    =
      {normal} identifier assign expression semicolon
        {-> New named_expression.normal(identifier, assign, expression) }
    |
      {selection} selection assign [selector_name]:identifier l_par [parameter]:identifier r_par semicolon
        {-> New named_expression.selection([selection.identifiers], assign, selector_name, parameter) }
    ;

  selection
        {-> [identifiers]:identifier+ }
    =
      l_par identifier [selection_additional_identifiers]:selection_additional_identifier+ r_par
        {-> [identifier, selection_additional_identifiers.identifier]}
    ;

  selection_additional_identifier
        {-> identifier }
    =
      bar identifier
        {-> identifier }
    ;

  expression
    =
      {simple} top_expression
        {-> top_expression.expression }
    |
      {or} expression bar top_expression
        {-> New expression.or(expression, bar, top_expression.expression) }
    ;

  top_expression
        {-> expression }
    =
      {simple} concatenation
        {-> concatenation.expression }
    |
      {look} concatenation look_keyword look_expression
        {-> New expression.look(concatenation.expression, look_keyword, look_expression.expression) }
    |
      {look_not} concatenation look_keyword not_keyword look_expression
        {-> New expression.look_not(concatenation.expression, look_keyword, not_keyword, look_expression.expression) }
    |
      {shortest} shortest_keyword concatenation
        {-> New expression.shortest(shortest_keyword, concatenation.expression) }
    |
      {longest} longest_keyword concatenation
        {-> New expression.longest(longest_keyword, concatenation.expression) }
    |
      {subtraction} [left]:concatenation minus [right]:concatenation
        {-> New expression.subtraction(left.expression, minus, right.expression) }
    |
      {difference} [left]:concatenation diff_keyword [right]:concatenation
        {-> New expression.difference(left.expression, diff_keyword, right.expression) }
    |
      {and} [left]:concatenation and_keyword [right]:concatenation
        {-> New expression.and(left.expression, and_keyword, right.expression) }
    |
      {interval} [from]:character two_dots [to]:character
        {-> New expression.interval(from, two_dots, to) }
    ;

  look_expression
        {-> expression }
    =
      {simple} concatenation
        {-> concatenation.expression }
    |
      {complete} concatenation end_keyword
        {-> New expression.concatenation(concatenation.expression, New expression.end(end_keyword)) }
    |
      {end} end_keyword
        {-> New expression.end(end_keyword) }
    ;

  concatenation
        {-> expression }
    =
      {simple} unary_expression
        {-> unary_expression.expression }
    |
      {complete} concatenation unary_expression
        {-> New expression.concatenation(concatenation.expression, unary_expression.expression) }
    ;

  unary_expression
        {-> expression }
    =
      {simple} term
        {-> term.expression }
    |
      {zero_or_one} term q_mark
        {-> New expression.zero_or_one(term.expression, q_mark) }
    |
      {zero_or_more} term star
        {-> New expression.zero_or_more(term.expression, star) }
    |
      {separated_zero_or_more} l_par [base]:concatenation separator_keyword [separator]:concatenation r_par star
        {-> New expression.separated_zero_or_more(base.expression, separator_keyword, separator.expression, star) }
    |
      {one_or_more} term plus
        {-> New expression.one_or_more(term.expression, plus) }
    |
      {separated_one_or_more} l_par [base]:concatenation separator_keyword [separator]:concatenation r_par plus
        {-> New expression.separated_one_or_more(base.expression, separator_keyword, separator.expression, plus) }
    |
      {number_exponent} term caret number
        {-> New expression.number_exponent(term.expression, caret, number) }
    |
      {separated_number_exponent} l_par [base]:concatenation separator_keyword [separator]:concatenation r_par caret number
        {-> New expression.separated_number_exponent(base.expression, separator_keyword, separator.expression, caret, number) }
    |
      {interval_exponent} term caret l_par [from]:number two_dots [to]:number r_par
        {-> New expression.interval_exponent(term.expression, caret, from, two_dots, to) }
    |
      {separated_interval_exponent} [l_par1]:l_par [base]:concatenation separator_keyword [separator]:concatenation [r_par1]:r_par caret [l_par2]:l_par [from]:number two_dots [to]:number [r_par2]:r_par
        {-> New expression.separated_interval_exponent(base.expression, separator_keyword, separator.expression, caret, from, two_dots, to) }
    |
      {at_least} term caret l_par number three_dots r_par
        {-> New expression.at_least(term.expression, caret, number, three_dots) }
    |
      {separated_at_least} [l_par1]:l_par [base]:concatenation separator_keyword [separator]:concatenation [r_par1]:r_par caret [l_par2]:l_par number three_dots [r_par2]:r_par
        {-> New expression.separated_at_least(base.expression, separator_keyword, separator.expression, caret, number, three_dots) }
    ;

  term
        {-> expression }
    =
      {name} identifier
        {-> New expression.name(identifier) }
    |
      {string} string
        {-> New expression.string(string) }
    |
      {char} char
        {-> New expression.char(char) }
    |
      {epsilon} epsilon
        {-> New expression.epsilon(epsilon) }
    |
      {dec} dec_char
        {-> New expression.dec(dec_char) }
    |
      {hex} hex_char
        {-> New expression.hex(hex_char) }
    |
      {any} any_keyword
        {-> New expression.any(any_keyword) }
    |
      {par} l_par expression r_par
        {-> expression }
    ;

  unit
    =
      {name} identifier
    |
      {string} string
    |
      {character} character
    |
      {epsilon} epsilon
    |
      {any} any_keyword
    ;

  character
    =
      {char} char
    |
      {dec} dec_char
    |
      {hex} hex_char
    ;

  unary_operator
    =
      {zero_or_one} q_mark
    |
      {many} many_operator
    ;

  many_operator
    =
      {zero_or_more} star
    |
      {one_or_more} plus
    |
      {number} caret number
    |
      {interval} caret l_par [from]:number two_dots [to]:number r_par
    |
      {at_least} caret l_par number three_dots r_par
    ;

  group
    =
      group_keyword identifier colon unit_list? semicolon
        {-> New group (group_keyword, identifier, colon, [unit_list.units]) }
    ;

  lexer_contexts
        {-> [lexer_contexts]:lexer_context+ }
    =
      lexer_default_context [lexer_named_contexts]:lexer_named_context*
        {-> [lexer_default_context.lexer_context, lexer_named_contexts.lexer_context] }
    ;

  lexer_default_context
        {-> lexer_context }
    =
      lexer_context_body
        {-> New lexer_context(Null, lexer_context_body.tokens, lexer_context_body.ignored, lexer_context_body.rejected, [lexer_context_body.lexer_priorities]) }
    ;

  lexer_named_context
        {-> lexer_context }
    =
      context_keyword identifier colon lexer_context_body
        {-> New lexer_context(identifier, lexer_context_body.tokens, lexer_context_body.ignored, lexer_context_body.rejected, [lexer_context_body.lexer_priorities]) }
    ;

  lexer_context_body
        {-> tokens? ignored? rejected? [lexer_priorities]:lexer_priority* }
    =
      tokens? ignored? rejected? lexer_priorities?
        {-> tokens ignored rejected [lexer_priorities.lexer_priorities] }
    ;

  tokens
    =
      token_keyword unit_list? semicolon
        {-> New tokens(token_keyword, [unit_list.units]) }
    ;

  ignored
    =
      ignored_keyword unit_list? semicolon
        {-> New ignored(ignored_keyword, [unit_list.units]) }
    ;

  rejected
    =
      rejected_keyword unit_list? semicolon
        {-> New rejected(rejected_keyword, [unit_list.units]) }
    ;

  unit_list
        {-> [units]:unit+ }
    =
      unit [additional_units]:additional_unit*
        {-> [unit, additional_units.unit] }
    ;

  additional_unit
        {-> unit }
    =
      comma unit
        {-> unit }
    ;

  lexer_priorities
        {-> [lexer_priorities]:lexer_priority* }
    =
      priority_keyword [lexer_priorities]:lexer_priority*
        {-> [lexer_priorities] }
    ;

  lexer_priority
    =
      [high]:unit gt [low]:unit semicolon
        {-> New lexer_priority(high, gt, low) }
    ;

  lexer_investigators
        {-> [lexer_investigators]:lexer_investigator* }
    =
      investigator_keyword [lexer_investigators]:lexer_investigator*
        {-> [lexer_investigators] }
    ;

  lexer_investigator
    =
      [name]:identifier l_par identifier r_par semicolon
        {-> New lexer_investigator(name, identifier) }
    ;

  parser
    =
      parser_keyword start parser_contexts inlined?
        {-> New parser(parser_keyword, start, [parser_contexts.parser_contexts], inlined) }
    ;

  start
    =
      normal_start? start_no_end?
    ;

  normal_start
    =
      start_keyword identifier_list? semicolon
        {-> New normal_start(start_keyword, [identifier_list.identifiers] ) }
    ;

  start_no_end
    =
      start_no_end_keyword identifier_list? semicolon
        {-> New start_no_end(start_no_end_keyword, [identifier_list.identifiers] ) }
    ;

  identifier_list
        {-> [identifiers]:identifier+ }
    =
      identifier [additional_identifiers]:additional_identifier*
        {-> [identifier, additional_identifiers.identifier] }
    ;

  additional_identifier
        {-> identifier }
    =
      comma identifier
        {-> identifier }
    ;

  parser_contexts
        {-> [parser_contexts]:parser_context+ }
    =
      parser_default_context [parser_named_contexts]:parser_named_context*
        {-> [parser_default_context.parser_context, parser_named_contexts.parser_context] }
    ;

  parser_default_context
        {-> parser_context }
    =
      [parser_productions]:parser_production*
        {-> New parser_context(Null, [parser_productions]) }
    ;

  parser_named_context
        {-> parser_context }
    =
      context_keyword identifier colon [parser_productions]:parser_production*
        {-> New parser_context(identifier, [parser_productions]) }
    ;

  parser_production
    =
      {normal} qualifier? parser_production_body parser_priorities? parser_investigator?
        {-> New parser_production.normal(qualifier, parser_production_body, [parser_priorities.parser_priorities], parser_investigator) }
    |
      {selection} selection assign identifier l_par identifier_list r_par
        {-> New parser_production.selection([selection.identifiers], assign, identifier, [identifier_list.identifiers]) }
    ;

  qualifier
    =
      {dangling} dangling_keyword
    |
      {token} token_keyword
    ;

  parser_production_body
    =
      identifier assign parser_alternatives semicolon
        {-> New parser_production_body(identifier, assign, [parser_alternatives.parser_alternatives]) }
    ;

  parser_alternatives
        {-> [parser_alternatives]:parser_alternative+ }
    =
      parser_alternative [additional_parser_alternatives]:additional_parser_alternative*
        {-> [parser_alternative, additional_parser_alternatives.parser_alternative] }
    ;

  additional_parser_alternative
        {-> parser_alternative }
    =
      bar parser_alternative
        {-> parser_alternative }
    ;

  parser_alternative
    =
      alternative_name? [elements]:element* parser_dangling_element?
    ;

  element
    =
      {normal} element_name? element_body unary_operator?
    |
      {separated} element_name? l_par [base]:element separator_keyword [separator]:element r_par many_operator
        {-> New element.separated(element_name, base, separator_keyword, separator, many_operator) }
    ;

  parser_dangling_element
    =
      dangling_keyword element_name? identifier q_mark
    ;

  element_body
    =
      {unit} unit
    |
      {par} l_par subalternatives r_par
        {-> New element_body.par(l_par, [subalternatives.subalternatives], r_par) }
    ;

  subalternatives
        {-> [subalternatives]:subalternative+ }
    =
      subalternative [additional_subalternatives]:additional_subalternative*
        {-> [subalternative, additional_subalternatives.subalternative] }
    ;

  additional_subalternative
        {-> subalternative }
    =
      bar subalternative
        {-> subalternative }
    ;

  subalternative
    =
      [elements]:element*
    ;

  parser_priorities
        {-> [parser_priorities]:parser_priority*}
    =
      priority_keyword [parser_priorities]:parser_priority*
        {-> [parser_priorities.parser_priority] }
    ;

  parser_priority
    =
      {left} left_keyword identifier_list semicolon
        {-> New parser_priority.left(left_keyword, [identifier_list.identifiers]) }
    |
      {right} right_keyword identifier_list semicolon
        {-> New parser_priority.right(right_keyword, [identifier_list.identifiers]) }
    ;

  parser_investigator
    =
      investigator_keyword [name]:identifier l_par identifier_list? r_par semicolon
        {-> New parser_investigator(investigator_keyword, name, [identifier_list.identifiers]) }
    ;

  inlined
    =
      inlined_keyword identifier_list? semicolon
        {-> New inlined(inlined_keyword, [identifier_list.identifiers]) }
    ;

  transformation
    =
      transformation_keyword production_transformations? alternative_transformations?
    ;

  production_transformations
    =
      production_keyword [production_transformations]:production_transformation*
    ;

  production_transformation
    =
      identifier arrow [elements]:element* semicolon
        {-> New production_transformation(identifier, arrow, [elements]) }
    ;

  alternative_transformations
    =
      alternative_keyword [alternative_transformations]:alternative_transformation*
    ;

  alternative_transformation
    =
      alternative_reference arrow [transformation_elements]:transformation_element* semicolon
        {-> New alternative_transformation(alternative_reference, arrow, [transformation_elements]) }
    ;

  alternative_reference
    =
      {unnamed} identifier
    |
      {named} [production]:identifier dot [alternative]:identifier
    ;

  transformation_element
    =
      {null} null_keyword
    |
      {reference} element_reference unary_operator?
    |
      {new} new_keyword alternative_reference l_par [transformation_elements]:transformation_element* r_par
    |
      {tuple} l_par [transformation_elements]:transformation_element* r_par
    ;

  element_reference
    =
      {direct} identifier
    |
      {nested} identifier dot [nested_name]:identifier
    ;

  tree
    =
      tree_keyword [tree_productions]:tree_production*
    ;

  tree_production
    =
      identifier assign tree_alternatives semicolon
        {-> New tree_production(identifier, assign, [tree_alternatives.tree_alternatives]) }
    ;

  tree_alternatives
        {-> [tree_alternatives]:tree_alternative+ }
    =
      tree_alternative [additional_tree_alternatives]:additional_tree_alternative*
        {-> [tree_alternative, additional_tree_alternatives.tree_alternative] }
    ;

  additional_tree_alternative
        {-> tree_alternative }
    =
      bar tree_alternative
        {-> tree_alternative }
    ;

  tree_alternative
    =
      alternative_name? [elements]:element*
    ;

Abstract Syntax Tree

  grammar
    =
      language_keyword [language_name]:identifier lexer? parser transformation? tree?
    ;

  lexer
    =
      lexer_keyword [named_expressions]:named_expression* [groups]:group* [lexer_contexts]:lexer_context+ [lexer_investigators]:lexer_investigator*
    ;

  named_expression
    =
      {normal} identifier assign expression
    |
      {selection} [names]:identifier+ assign [selector_name]:identifier [parameter]:identifier
    ;

  expression
    =
      {or} [left]:expression bar [right]:expression
    |
      {concatenation} [left]:expression [right]:expression
    |
      {look} [left]:expression look_keyword [right]:expression
    |
      {look_not} [left]:expression look_keyword not_keyword [right]:expression
    |
      {shortest} shortest_keyword expression
    |
      {longest} longest_keyword expression
    |
      {subtraction} [left]:expression minus [right]:expression
    |
      {difference} [left]:expression diff_keyword [right]:expression
    |
      {and} [left]:expression and_keyword [right]:expression
    |
      {zero_or_one} expression q_mark
    |
      {zero_or_more} expression star
    |
      {separated_zero_or_more} [base]:expression separator_keyword [separator]:expression star
    |
      {one_or_more} expression plus
    |
      {separated_one_or_more} [base]:expression separator_keyword [separator]:expression plus
    |
      {number_exponent} expression caret number
    |
      {separated_number_exponent} [base]:expression separator_keyword [separator]:expression caret number
    |
      {interval_exponent} expression caret [from]:number two_dots [to]:number
    |
      {separated_interval_exponent} [base]:expression separator_keyword [separator]:expression caret [from]:number two_dots [to]:number
    |
      {at_least} expression caret number three_dots
    |
      {separated_at_least} [base]:expression separator_keyword [separator]:expression caret number three_dots
    |
      {name} identifier
    |
      {string} string
    |
      {char} char
    |
      {epsilon} epsilon
    |
      {dec} dec_char
    |
      {hex} hex_char
    |
      {interval} [from]:character two_dots [to]:character
    |
      {any} any_keyword
    |
      {end} end_keyword
    ;

  character
    =
      {char} char
    |
      {dec} dec_char
    |
      {hex} hex_char
    ;

  group
    =
      group_keyword [name]:identifier colon unit*
    ;

  unit
    =
      {name} identifier
    |
      {string} string
    |
      {character} character
    |
      {epsilon} epsilon
    |
      {any} any_keyword
    ;

  lexer_context
    =
      [name]:identifier? tokens? ignored? rejected? [lexer_priorities]:lexer_priority*
    ;

  tokens
    =
      token_keyword unit*
    ;

  ignored
    =
      ignored_keyword unit*
    ;

  rejected
    =
      rejected_keyword unit*
    ;

  lexer_priority
    =
      [high]:unit gt [low]:unit
    ;

  lexer_investigator
    =
      [name]:identifier [parameter]:identifier
    ;

  parser
    =
      parser_keyword start [parser_contexts]:parser_context+ inlined?
    ;

  start
    =
      normal_start? start_no_end?
    ;

  normal_start
    =
      start_keyword [identifiers]:identifier*
    ;

  start_no_end
    =
      start_no_end_keyword [identifiers]:identifier*
    ;

  parser_context
    =
      [name]:identifier? [parser_productions]:parser_production*
    ;

  parser_production
    =
      {normal} qualifier? parser_production_body [parser_priorities]:parser_priority* parser_investigator?
    |
      {selection} [names]:identifier+ assign [selector_name]:identifier [parameters]:identifier+
    ;

  qualifier
    =
      {dangling} dangling_keyword
    |
      {token} token_keyword
    ;

  parser_production_body
    =
      identifier assign [parser_alternatives]:parser_alternative+
    ;

  parser_alternative
    =
      alternative_name? [elements]:element* parser_dangling_element?
    ;

  element
    =
      {normal} element_name? element_body unary_operator?
    |
      {separated} element_name? [base]:element separator_keyword [separator]:element many_operator
    ;

  unary_operator
    =
      {zero_or_one} q_mark
    |
      {many} many_operator
    ;

  many_operator
    =
      {zero_or_more} star
    |
      {one_or_more} plus
    |
      {number} caret number
    |
      {interval} caret l_par [from]:number two_dots [to]:number r_par
    |
      {at_least} caret l_par number three_dots r_par
    ;

  parser_dangling_element
    =
      dangling_keyword element_name? identifier q_mark
    ;

  element_body
    =
      {unit} unit
    |
      {par} l_par [subalternatives]:subalternative+ r_par
    ;

  subalternative
    =
      [elements]:element*
    ;

  parser_priority
    =
      {left} left_keyword [identifiers]:identifier+
    |
      {right} right_keyword [identifiers]:identifier+
    ;

  parser_investigator
    =
      investigator_keyword [name]:identifier [parameters]:identifier*
    ;

  inlined
    =
      inlined_keyword [identifiers]:identifier*
    ;

  transformation
    =
      transformation_keyword production_transformations? alternative_transformations?
    ;

  production_transformations
    =
      production_keyword [production_transformations]:production_transformation*
    ;

  production_transformation
    =
      identifier arrow [elements]:element*
    ;

  alternative_transformations
    =
      alternative_keyword [alternative_transformations]:alternative_transformation*
    ;

  alternative_transformation
    =
      alternative_reference arrow [transformation_elements]:transformation_element*
    ;

  alternative_reference
    =
      {unnamed} identifier
    |
      {named} [production]:identifier dot [alternative]:identifier
    ;

  transformation_element
    =
      {null} null_keyword
    |
      {reference} element_reference unary_operator?
    |
      {new} new_keyword alternative_reference l_par [transformation_elements]:transformation_element* r_par
    |
      {tuple} l_par [transformation_elements]:transformation_element* r_par
    ;

  element_reference
    =
      {direct} identifier
    |
      {nested} identifier dot [nested_name]:identifier
    ;

  tree
    =
      tree_keyword [tree_productions]:tree_production*
    ;

  tree_production
    =
      identifier assign [tree_alternatives]:tree_alternative+
    ;

  tree_alternative
    =
      alternative_name? [elements]:element*
    ;
