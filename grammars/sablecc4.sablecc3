/* This file is part of SableCC ( http://sablecc.org ).
 *
 * See the NOTICE file distributed with this work for copyright information.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

Package org.sablecc.sablecc.syntax3;

Helpers

  // Based on Unicode 5.1.0

  ascii_lu = [0x0041 .. 0x005A];
  ascii_ll = [0x0061 .. 0x007A];

  ascii_l = [ascii_lu + ascii_ll];

  ascii_nd = [0x0030 .. 0x0039];

  ascii_n = ascii_nd;

  ascii_pc = 0x005F;
  ascii_pd = 0x002D;
  ascii_ps = [[0x0028 + 0x005B] + 0x007B];
  ascii_pe = [[0x0029 + 0x005D] + 0x007D];
  ascii_po = [[[[0x0021 .. 0x0023] + [0x0025 .. 0x0027]] +
               [[0x002A + 0x002C] + [0x002E .. 0x002F]]] +
              [[[0x003A .. 0x003B] + [0x003F .. 0x0040]] + 0x005C]];

  ascii_p = [[[ascii_pc + ascii_pd] + [ascii_ps + ascii_pe]] + ascii_po];

  ascii_sm = [[0x002B + [0x003C .. 0x003E]] + [0x007C + 0x007E]];
  ascii_sc = 0x0024;
  ascii_sk = [0x005E + 0x0060];

  ascii_s = [[ascii_sm + ascii_sc] + ascii_sk];

  ascii_zs = 0x0020;

  ascii_z = ascii_zs;

  ascii_cc = [[0x0000 .. 0x001F] + 0x007F];

  ascii_c = ascii_cc;

  ascii = [[[ascii_l + ascii_n] + [ascii_p + ascii_s]] + [ascii_z + ascii_c]];

  ascii_pattern_white_space = [[0x0009 .. 0x000D] + 0x0020];
  ascii_pattern_syntax = [[[[0x0021 .. 0x002F] + [0x003A .. 0x0040]] +
                          [[0x005B .. 0x005E] + 0x0060]] + [0x007B .. 0x007E]];

  ascii_id_start = [[0x0041 .. 0x005A] + [0x0061 .. 0x007A]];
  ascii_id_continue = [[[0x0030 .. 0x0039] + [0x0041 .. 0x005A]] +
                       [0x005F + [0x0061 .. 0x007A]]];

  ascii_identifier = ascii_id_start ascii_id_continue*;

  ascii_newline = [0x000A .. 0x000D] | 0x000D 0x000A;

  // Other helpers

  single_char = [[[ascii - ascii_c] + ascii_pattern_white_space] -
                 [[0x000A .. 0x000D] + [''' + '\']]];
  char_escape = '\' [''' + '\'];

  line_comment_char = [[[ascii - ascii_c] + ascii_pattern_white_space] -
                       [[0x000A .. 0x000D] + '\']];
  line_comment_escape = '\' '\';

  long_comment_char = [[[ascii - ascii_c] + ascii_pattern_white_space] -
                       [['*' + '/'] + '\']];
  long_comment_escape = '\' ['*' + '\'];

  decimal_digit = ['0' .. '9'];
  hexadecimal_digit = [decimal_digit + [['A' .. 'F'] + ['a' .. 'f']]];

  sign = ['+' + '-'];
  x = ['X' + 'x'];

Tokens

  alternative_keyword = '$alternative';
  and_keyword = '$and';
  any_keyword = '$any';
  context_keyword = '$context';
  dangling_keyword = '$dangling';
  diff_keyword = '$diff';
  end_keyword = '$end';
  group_keyword = '$group';
  ignored_keyword = '$ignored';
  inlined_keyword = '$inlined';
  investigator_keyword = '$investigator';
  language_keyword = '$language';
  left_keyword = '$left';
  lexer_keyword = '$lexer';
  longest_keyword = '$longest';
  look_keyword = '$look';
  not_keyword = '$not';
  new_keyword = '$new';
  null_keyword = '$null';
  parser_keyword = '$parser';
  priority_keyword = '$priority';
  production_keyword = '$production';
  rejected_keyword = '$rejected';
  right_keyword = '$right';
  separator_keyword = '$separator';
  shortest_keyword = '$shortest';
  start_keyword = '$start';
  start_no_end_keyword = '$start_no_end';
  token_keyword = '$token';
  transformation_keyword = '$transformation';
  tree_keyword = '$tree';

  identifier = ascii_identifier;

  alternative_name = '{' ascii_identifier ':}';
  element_name = '[' ascii_identifier ':]';

  char = ''' (single_char | char_escape) ''';
  string = ''' (single_char | char_escape)* ''';
  number = decimal_digit+;

  dec_char = '#' sign? decimal_digit+;
  hex_char = '#' x sign? hexadecimal_digit+;

  l_par = '(';
  r_par =')';

  assign = '=';
  arrow = '->';
  bar = '|';
  caret = '^';
  colon = ':';
  comma = ',';
  dot = '.';
  gt = '>';
  minus = '-';
  plus = '+';
  q_mark = '?';
  semicolon = ';';
  star = '*';
  three_dots = '...';
  two_dots = '..';

  blank = ascii_pattern_white_space+;

  line_comment = '//' (line_comment_char | line_comment_escape)*
                 ascii_newline?;

  long_comment = '/*' ([long_comment_char + '/'] | long_comment_escape)*
                 ('*' ((long_comment_char | long_comment_escape)
                       ([long_comment_char + '/'] | long_comment_escape)*)?)*
                 '*/';

  ctrl_z = 0x001A;

  invalid_keyword = '$' ascii_identifier;
  invalid_number = decimal_digit+ ascii_identifier;
  invalid_string = ''' (single_char | char_escape)*;
  invalid_dec_char = '#' sign? decimal_digit+ ascii_identifier;
  invalid_hex_char = '#' x sign? hexadecimal_digit+ ascii_identifier;

Ignored Tokens

  blank, line_comment, long_comment;

Productions

  grammar
    =
      language_name lexer? parser transformation? tree? ctrl_z?
        {-> New grammar(language_name.identifier, lexer, parser, transformation, tree) }
    ;

  language_name
        {-> identifier }
    =
      language_keyword identifier semicolon
        {-> identifier }
    ;

  lexer
    =
      lexer_keyword [named_expressions]:named_expression* [groups]:group* lexer_contexts lexer_investigators
        {-> New lexer(lexer_keyword, [named_expressions], [groups], [lexer_contexts.lexer_contexts], [lexer_investigators.lexer_investigators]) }
    ;

  named_expression
    =
      {normal} identifier assign expression semicolon
    |
      {selection} selection assign [name]:identifier l_par identifier r_par semicolon
    ;

  selection
    =
      l_par identifier [selection_additional_identifiers]:selection_additional_identifier+ r_par
    ;

  selection_additional_identifier
    =
      bar identifier
    ;

  expression
    =
      top_expression [additional_top_expressions]:additional_top_expression*
    ;

  additional_top_expression
    =
      bar top_expression
    ;

  top_expression
    =
      {simple} concatenation
    |
      {interval} [from]:character two_dots [to]:character
    |
      {look} concatenation look_keyword look_expression
    |
      {looknot} concatenation look_keyword not_keyword look_expression
    |
      {shortest} shortest_keyword concatenation
    |
      {longest} longest_keyword concatenation
    |
      {exclusion} [left]:concatenation minus [right]:concatenation
    |
      {difference} [left]:concatenation diff_keyword [right]:concatenation
    |
      {intersection} [left]:concatenation and_keyword [right]:concatenation
    ;

  look_expression
    =
      {middle} concatenation end_keyword?
    |
      {end} end_keyword
    ;

  concatenation
    =
      [unary_expressions]:unary_expression+
    ;

  unary_expression
    =
      {normal} term unary_operator?
    |
      {separated} l_par [left]:concatenation separator_keyword [right]:concatenation r_par many_operator
    ;

  unary_operator
    =
      {zero_or_one} q_mark
    |
      {many} many_operator
    ;

  many_operator
    =
      {zero_or_more} star
    |
      {one_or_more} plus
    |
      {number} caret number
    |
      {interval} caret l_par [from]:number two_dots [to]:number r_par
    |
      {at_least} caret l_par number three_dots r_par
    ;

  term
    =
      {unit} unit
    |
      {par} l_par expression r_par
    ;

  unit
    =
      {name} identifier
    |
      {string} string
    |
      {character} character
    |
      {any} any_keyword
    ;

  character
    =
      {literal} char
    |
      {dec} dec_char
    |
      {hex} hex_char
    ;

  group
    =
      group_keyword identifier colon unit_list? semicolon
    ;

  lexer_contexts
        {-> [lexer_contexts]:lexer_context+ }
    =
      lexer_default_context [lexer_named_contexts]:lexer_named_context*
        {-> [lexer_default_context.lexer_context, lexer_named_contexts.lexer_context] }
    ;

  lexer_default_context
        {-> lexer_context }
    =
      lexer_context_body
        {-> New lexer_context(Null, lexer_context_body.tokens, lexer_context_body.ignored, lexer_context_body.rejected, lexer_context_body.lexer_priorities) }
    ;

  lexer_named_context
        {-> lexer_context }
    =
      context_keyword identifier colon lexer_context_body
        {-> New lexer_context(identifier, lexer_context_body.tokens, lexer_context_body.ignored, lexer_context_body.rejected, lexer_context_body.lexer_priorities) }
    ;

  lexer_context_body
        {-> tokens? ignored? rejected? lexer_priorities? }
    =
      tokens? ignored? rejected? lexer_priorities?
        {-> tokens ignored rejected lexer_priorities }
    ;

  tokens
    =
      token_keyword unit_list? semicolon
    ;

  ignored
    =
      ignored_keyword unit_list? semicolon
    ;

  rejected
    =
      rejected_keyword unit_list? semicolon
    ;

  unit_list
    =
      unit [additional_units]:additional_unit*
    ;

  additional_unit
    =
      comma unit
    ;

  lexer_priorities
    =
      priority_keyword [lexer_priorities]:lexer_priority*
    ;

  lexer_priority
    =
      [high]:unit gt [low]:unit semicolon
    ;

  lexer_investigators
        {-> [lexer_investigators]:lexer_investigator* }
    =
      investigator_keyword [lexer_investigators]:lexer_investigator*
        {-> [lexer_investigators] }
    ;

  lexer_investigator
    =
      [name]:identifier l_par identifier r_par semicolon
    ;

  parser
    =
      parser_keyword start parser_contexts inlined?
    ;

  start
    =
      normal_start? start_no_end?
    ;

  normal_start
    =
      start_keyword identifier_list? semicolon
    ;

  start_no_end
    =
      start_no_end_keyword identifier_list? semicolon
    ;

  identifier_list
    =
      identifier [additional_identifiers]:additional_identifier*
    ;

  additional_identifier
    =
      comma identifier
    ;

  parser_contexts
    =
      parser_default_context [parser_named_contexts]:parser_named_context*
    ;

  parser_default_context
    =
      [parser_productions]:parser_production*
    ;

  parser_named_context
    =
      context_keyword identifier colon [parser_productions]:parser_production*
    ;

  parser_production
    =
      {normal} qualifier? parser_production_body parser_priorities? parser_investigator?
    |
      {selection} selection assign identifier l_par identifier_list r_par
    ;

  qualifier
    =
      {dangling} dangling_keyword
    |
      {token} token_keyword
    ;

  parser_production_body
    =
      identifier assign parser_alternatives semicolon
    ;

  parser_alternatives
    =
      parser_alternative [additional_parser_alternatives]:additional_parser_alternative*
    ;

  additional_parser_alternative
    =
      bar parser_alternative
    ;

  parser_alternative
    =
      alternative_name? [elements]:element* parser_dangling_element?
    ;

  element
    =
      {normal} element_name? element_body unary_operator?
    |
      {separated} element_name? l_par [left]:element separator_keyword [right]:element r_par many_operator
    ;

  parser_dangling_element
    =
      dangling_keyword element_name? identifier q_mark
    ;

  element_body
    =
      {unit} unit
    |
      {par} l_par subalternatives r_par
    ;

  subalternatives
    =
      subalternative [additional_subalternatives]:additional_subalternative*
    ;

  additional_subalternative
    =
      bar subalternative
    ;

  subalternative
    =
      [elements]:element*
    ;

  parser_priorities
    =
      priority_keyword [parser_priorities]:parser_priority*
    ;

  parser_priority
    =
      {left} left_keyword identifier_list semicolon
    |
      {right} right_keyword identifier_list semicolon
    ;

  parser_investigator
    =
      investigator_keyword identifier l_par identifier_list? r_par semicolon
    ;

  inlined
    =
      inlined_keyword identifier_list? semicolon
    ;

  transformation
    =
      transformation_keyword production_transformations? alternative_transformations?
    ;

  production_transformations
    =
      production_keyword [production_transformations]:production_transformation*
    ;

  production_transformation
    =
      identifier arrow [elements]:element* semicolon
    ;

  alternative_transformations
    =
      alternative_keyword [alternative_transformations]:alternative_transformation*
    ;

  alternative_transformation
    =
      alternative_reference arrow [transformation_elements]:transformation_element* semicolon
    ;

  alternative_reference
    =
      {unnamed} identifier
    |
      {named} [production]:identifier dot [alternative]:identifier
    ;

  transformation_element
    =
      {null} null_keyword
    |
      {reference} element_reference unary_operator?
    |
      {new} new_keyword alternative_reference l_par [transformation_elements]:transformation_element* r_par
    |
      {tuple} l_par [transformation_elements]:transformation_element* r_par
    ;

  element_reference
    =
      {direct} identifier
    |
      {nested} identifier dot [nested_name]:identifier
    ;

  tree
    =
      tree_keyword [tree_productions]:tree_production*
    ;

  tree_production
    =
      identifier assign tree_alternatives semicolon
    ;

  tree_alternatives
    =
      tree_alternative [additional_tree_alternatives]:additional_tree_alternative*
    ;

  additional_tree_alternative
    =
      bar tree_alternative
    ;

  tree_alternative
    =
      alternative_name? [elements]:element*
    ;

Abstract Syntax Tree

  grammar
    =
      [language_name]:identifier lexer? parser transformation? tree?
    ;

  lexer
    =
      lexer_keyword [named_expressions]:named_expression* [groups]:group* [lexer_contexts]:lexer_context+ [lexer_investigators]:lexer_investigator*
    ;

  named_expression
    =
      {normal} identifier assign expression semicolon
    |
      {selection} selection assign [name]:identifier l_par identifier r_par semicolon
    ;

  selection
    =
      l_par identifier [selection_additional_identifiers]:selection_additional_identifier+ r_par
    ;

  selection_additional_identifier
    =
      bar identifier
    ;

  expression
    =
      top_expression [additional_top_expressions]:additional_top_expression*
    ;

  additional_top_expression
    =
      bar top_expression
    ;

  top_expression
    =
      {simple} concatenation
    |
      {interval} [from]:character two_dots [to]:character
    |
      {look} concatenation look_keyword look_expression
    |
      {looknot} concatenation look_keyword not_keyword look_expression
    |
      {shortest} shortest_keyword concatenation
    |
      {longest} longest_keyword concatenation
    |
      {exclusion} [left]:concatenation minus [right]:concatenation
    |
      {difference} [left]:concatenation diff_keyword [right]:concatenation
    |
      {intersection} [left]:concatenation and_keyword [right]:concatenation
    ;

  look_expression
    =
      {middle} concatenation end_keyword?
    |
      {end} end_keyword
    ;

  concatenation
    =
      [unary_expressions]:unary_expression+
    ;

  unary_expression
    =
      {normal} term unary_operator?
    |
      {separated} l_par [left]:concatenation separator_keyword [right]:concatenation r_par many_operator
    ;

  unary_operator
    =
      {zero_or_one} q_mark
    |
      {many} many_operator
    ;

  many_operator
    =
      {zero_or_more} star
    |
      {one_or_more} plus
    |
      {number} caret number
    |
      {interval} caret l_par [from]:number two_dots [to]:number r_par
    |
      {at_least} caret l_par number three_dots r_par
    ;

  term
    =
      {unit} unit
    |
      {par} l_par expression r_par
    ;

  unit
    =
      {name} identifier
    |
      {string} string
    |
      {character} character
    |
      {any} any_keyword
    ;

  character
    =
      {literal} char
    |
      {dec} dec_char
    |
      {hex} hex_char
    ;

  group
    =
      group_keyword identifier colon unit_list? semicolon
    ;

  lexer_context
    =
      [name]:identifier? tokens? ignored? rejected? lexer_priorities?
    ;

  tokens
    =
      token_keyword unit_list? semicolon
    ;

  ignored
    =
      ignored_keyword unit_list? semicolon
    ;

  rejected
    =
      rejected_keyword unit_list? semicolon
    ;

  unit_list
    =
      unit [additional_units]:additional_unit*
    ;

  additional_unit
    =
      comma unit
    ;

  lexer_priorities
    =
      priority_keyword [lexer_priorities]:lexer_priority*
    ;

  lexer_priority
    =
      [high]:unit gt [low]:unit semicolon
    ;

  lexer_investigator
    =
      [name]:identifier l_par identifier r_par semicolon
    ;

  parser
    =
      parser_keyword start parser_contexts inlined?
    ;

  start
    =
      normal_start? start_no_end?
    ;

  normal_start
    =
      start_keyword identifier_list? semicolon
    ;

  start_no_end
    =
      start_no_end_keyword identifier_list? semicolon
    ;

  identifier_list
    =
      identifier [additional_identifiers]:additional_identifier*
    ;

  additional_identifier
    =
      comma identifier
    ;

  parser_contexts
    =
      parser_default_context [parser_named_contexts]:parser_named_context*
    ;

  parser_default_context
    =
      [parser_productions]:parser_production*
    ;

  parser_named_context
    =
      context_keyword identifier colon [parser_productions]:parser_production*
    ;

  parser_production
    =
      {normal} qualifier? parser_production_body parser_priorities? parser_investigator?
    |
      {selection} selection assign identifier l_par identifier_list r_par
    ;

  qualifier
    =
      {dangling} dangling_keyword
    |
      {token} token_keyword
    ;

  parser_production_body
    =
      identifier assign parser_alternatives semicolon
    ;

  parser_alternatives
    =
      parser_alternative [additional_parser_alternatives]:additional_parser_alternative*
    ;

  additional_parser_alternative
    =
      bar parser_alternative
    ;

  parser_alternative
    =
      alternative_name? [elements]:element* parser_dangling_element?
    ;

  element
    =
      {normal} element_name? element_body unary_operator?
    |
      {separated} element_name? l_par [left]:element separator_keyword [right]:element r_par many_operator
    ;

  parser_dangling_element
    =
      dangling_keyword element_name? identifier q_mark
    ;

  element_body
    =
      {unit} unit
    |
      {par} l_par subalternatives r_par
    ;

  subalternatives
    =
      subalternative [additional_subalternatives]:additional_subalternative*
    ;

  additional_subalternative
    =
      bar subalternative
    ;

  subalternative
    =
      [elements]:element*
    ;

  parser_priorities
    =
      priority_keyword [parser_priorities]:parser_priority*
    ;

  parser_priority
    =
      {left} left_keyword identifier_list semicolon
    |
      {right} right_keyword identifier_list semicolon
    ;

  parser_investigator
    =
      investigator_keyword identifier l_par identifier_list? r_par semicolon
    ;

  inlined
    =
      inlined_keyword identifier_list? semicolon
    ;

  transformation
    =
      transformation_keyword production_transformations? alternative_transformations?
    ;

  production_transformations
    =
      production_keyword [production_transformations]:production_transformation*
    ;

  production_transformation
    =
      identifier arrow [elements]:element* semicolon
    ;

  alternative_transformations
    =
      alternative_keyword [alternative_transformations]:alternative_transformation*
    ;

  alternative_transformation
    =
      alternative_reference arrow [transformation_elements]:transformation_element* semicolon
    ;

  alternative_reference
    =
      {unnamed} identifier
    |
      {named} [production]:identifier dot [alternative]:identifier
    ;

  transformation_element
    =
      {null} null_keyword
    |
      {reference} element_reference unary_operator?
    |
      {new} new_keyword alternative_reference l_par [transformation_elements]:transformation_element* r_par
    |
      {tuple} l_par [transformation_elements]:transformation_element* r_par
    ;

  element_reference
    =
      {direct} identifier
    |
      {nested} identifier dot [nested_name]:identifier
    ;

  tree
    =
      tree_keyword [tree_productions]:tree_production*
    ;

  tree_production
    =
      identifier assign tree_alternatives semicolon
    ;

  tree_alternatives
    =
      tree_alternative [additional_tree_alternatives]:additional_tree_alternative*
    ;

  additional_tree_alternative
    =
      bar tree_alternative
    ;

  tree_alternative
    =
      alternative_name? [elements]:element*
    ;
