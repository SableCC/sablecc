/* This file is part of SableCC ( http://sablecc.org ).
 *
 * See the NOTICE file distributed with this work for copyright information.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

Package org.sablecc.sablecc.syntax3;

Helpers

  all = [0 .. 0xffff];

  carriage_return = 13;
  line_feed       = 10;
  tab             = 9;
  white_space     = ' ';

  end_of_line     =
    carriage_return |
    line_feed |
    carriage_return line_feed;

  decimal_digit     = ['0' .. '9'];
  hexadecimal_digit = [[decimal_digit + ['A' .. 'F']] + ['a' .. 'f']];
  lower_case_letter = ['a' .. 'z'];
  upper_case_letter = ['A' .. 'Z'];

  string_character  = [all - [[carriage_return + line_feed] + ''']];

  identifier_part = lower_case_letter (lower_case_letter | decimal_digit)*;

  not_star_slash = [all - ['/' + '*']];

Tokens

  // keywords

  all_keyword           = 'All';
  back_keyword          = 'Back';
  except_keyword        = 'Except';
  group_keyword         = 'Group';
  helpers_keyword       = 'Helpers';
  ignored_keyword       = 'Ignored';
  infinite_keyword      = 'Infinite';
  internal_keyword      = 'Internal';
  intersection_keyword  = 'Intersection';
  investigators_keyword = 'Investigators';
  language_keyword      = 'Language';
  lookahead_keyword     = 'Lookahead';
  lexer_keyword         = 'Lexer';
  none_keyword          = 'None';
  over_keyword          = 'Over';
  priorities_keyword    = 'Priorities';
  shortest_keyword      = 'Shortest';
  state_keyword         = 'State';
  states_keyword        = 'States';
  syntax_keyword        = 'Syntax';
  tokens_keyword        = 'Tokens';
  transitions_keyword   = 'Transitions';

  // separators

  colon      = ':';
  comma      = ',';
  semicolon  = ';';
  dot_dot    = '..';
  three_dots = '...';

  arrow_tail = '->(';
  arrow_head = ')->';

  left_bracket  = '[';
  right_bracket = ']';

  left_parenthesis  = '(';
  right_parenthesis = ')';

  // operators

  assign        = '=';
  bar           = '|';
  minus         = '-';
  plus          = '+';
  question_mark = '?';
  star          = '*';

  // identifier, numbers, strings and character

  identifier = identifier_part ('_' identifier_part)*;

  erroneous_identifier =
    (lower_case_letter | upper_case_letter | '_') (lower_case_letter | upper_case_letter | '_' | decimal_digit)*;

  decimal_number     = decimal_digit+;
  hexadecimal_number = '0' ('x' | 'X') hexadecimal_digit+;

  empty_string    = ''' ''';
  character_token = ''' (string_character | ''') ''';
  string          = ''' string_character string_character+ ''';

  // comments

  comment = '/*' not_star_slash* ('*'+ not_star_slash+ | '/'+ not_star_slash+)* '*'* '*/';

  // blanks

  blank = (white_space | tab | end_of_line)+;

Ignored Tokens

  blank;

Productions

  // specification

  specification =
    comment? header lexer  {-> New specification(header, lexer) };

  // header

  header =
    language syntax  {-> New header(language, syntax) };

  language =
    language_keyword [name]:identifier semicolon  {-> New language(name) };

  syntax =
    syntax_keyword [version]:decimal_number semicolon {-> New syntax(version) };

  // lexer

  lexer =
    {no_states} lexer_keyword helpers? tokens investigators? priorities? ignored? lookahead?  {-> New lexer.no_states(helpers, tokens, investigators, priorities, ignored, lookahead) } |
    {states}    lexer_keyword helpers? tokens investigators? states  {-> New lexer.states(helpers, tokens, investigators, states) };

  // helpers

  helpers =
    helpers_keyword [helpers]:helper+  {-> New helpers([helpers]) };

  helper =
    comment? [name]:identifier assign regular_expression semicolon  {-> New helper(name, regular_expression) };

  // tokens

  tokens =
    {normal} tokens_keyword [tokens]:token+  {-> New tokens.normal([tokens]) } |
    {groups} tokens_keyword [groups]:group+  {-> New tokens.groups([groups]) };

  group =
    group_keyword [name]:identifier colon [tokens]:token+  {-> New group(name, [tokens]) };

  token =
    {simple}    comment? [name]:identifier assign regular_expression three_dots? semicolon  {-> New token.simple(name, regular_expression, three_dots) } |
    {selection} comment? selection colon selector assign regular_expression three_dots? semicolon  {-> New token.selection(selection, selector, regular_expression, three_dots) };

  selection =
    [name]:identifier [additional_names]:additional_identifier+  {-> New selection([name, additional_names.identifier]) };

  selector =
    [name]:identifier left_parenthesis right_parenthesis  {-> New selector(name) };

  // priorities

  priorities =
    priorities_keyword [priorities]:priority+  {-> New priorities([priorities]) };

  priority =
    comment? [high_tokens]:token_collection over_keyword [low_tokens]:token_collection semicolon  {-> New priority(high_tokens, low_tokens) };

  // investigators

  investigators =
    investigators_keyword [investigators]:investigator+  {-> New investigators([investigators]) };

  investigator =
    comment? token_collection colon [name]:identifier left_parenthesis right_parenthesis semicolon  {-> New investigator(token_collection, name) };

  // states

  states =
    states_keyword [normal_states]:normal_state+ internal_states?  {-> New states([normal_states], internal_states) };

  normal_state =
    state_keyword [name]:identifier colon token_collection semicolon priorities? ignored? lookahead?  {-> New normal_state(name, token_collection, priorities, ignored, lookahead) };

  lookahead =
    {none}     lookahead_keyword none_keyword semicolon  {-> New lookahead.none() } |
    {infinite} lookahead_keyword infinite_keyword semicolon  {-> New lookahead.infinite() };

  ignored =
    ignored_keyword identifier [additional_identifiers]:additional_identifier* semicolon  {-> New ignored([identifier, additional_identifiers.identifier]) };

  internal_states =
    internal_keyword [internal_states]:internal_state+ transitions?  {-> New internal_states([internal_states], transitions) };

  internal_state =
    state_keyword [name]:identifier colon token_collection semicolon priorities? lookahead?  {-> New internal_state(name, token_collection, priorities, lookahead) };

  transitions =
    transitions_keyword [transitions]:transition+  {-> New transitions([transitions]) };

  transition =
    {normal} comment? [source]:identifier arrow_tail token_collection arrow_head [destination]:identifier semicolon  {-> New transition.normal(source, token_collection, destination) } |
    {back}   comment? [source]:identifier arrow_tail token_collection arrow_head back_keyword semicolon  {-> New transition.back(source, token_collection) };

  // regular expression

  regular_expression =
    {union}  regular_expression bar sub_expression  {-> New regular_expression.union(regular_expression, sub_expression.regular_expression) } |
    {simple} sub_expression  {-> sub_expression.regular_expression };

  sub_expression  {-> regular_expression } =
    {subtraction} sub_expression minus factor  {-> New regular_expression.subtraction(sub_expression.regular_expression, factor.regular_expression) } |
    {simple}      factor  {-> factor.regular_expression };

  factor  {-> regular_expression } =
    {concatenation} factor unary_expression  {-> New regular_expression.concatenation(factor.regular_expression, unary_expression.regular_expression) } |
    {simple}        unary_expression  {-> unary_expression.regular_expression };

  unary_expression  {-> regular_expression } =
    {zero_or_one}  term question_mark  {-> New regular_expression.zero_or_one(term.regular_expression) } |
    {zero_or_more} term star  {-> New regular_expression.zero_or_more(term.regular_expression) } |
    {one_or_more}  term plus  {-> New regular_expression.one_or_more(term.regular_expression) } |
    {simple}       term  {-> term.regular_expression };

  term  {-> regular_expression } =
    {intersection}  intersection_keyword left_parenthesis [left_regular_expression]:regular_expression comma [right_regular_expression]:regular_expression right_parenthesis  {-> New regular_expression.intersection(left_regular_expression, right_regular_expression) } |
    {shortest}      shortest_keyword left_parenthesis regular_expression right_parenthesis  {-> New regular_expression.shortest(regular_expression) } |
    {parenthesized} left_parenthesis regular_expression right_parenthesis  {-> regular_expression } |
    {interval}      left_bracket [lower_bound]:character dot_dot [upper_bound]:character right_bracket  {-> New regular_expression.interval(lower_bound, upper_bound) } |
    {string}        string  {-> New regular_expression.string(string) } |
    {character}     character  {-> New regular_expression.character(character) } |
    {empty_string}  empty_string  {-> New regular_expression.empty_string() } |
    {helper}        identifier  {-> New regular_expression.helper(identifier) };

  character =
    {character}   character_token |
    {decimal}     decimal_number |
    {hexadecimal} hexadecimal_number;

  // token collection

  token_collection =
    {complete}  all_keyword  {-> New token_collection.complete() } |
    {inclusive} identifier [additional_identifiers]:additional_identifier*  {-> New token_collection.inclusive([identifier, additional_identifiers.identifier]) } |
    {exclusive} all_keyword except_keyword identifier [additional_identifiers]:additional_identifier*  {-> New token_collection.exclusive([identifier, additional_identifiers.identifier]) };

  // additional identifier

  additional_identifier  {-> identifier } =
    comma identifier  {-> identifier};

Abstract Syntax Tree

  specification =
    header lexer;

  header =
    language syntax;

  language =
    [name]:identifier;

  syntax =
    [version]:decimal_number;

  lexer =
    {no_states} helpers? tokens investigators? priorities? ignored? lookahead? |
    {states}    helpers? tokens investigators? states;

  helpers =
    [helpers]:helper+;

  helper =
    [name]:identifier regular_expression;

  tokens =
    {normal} [tokens]:token+ |
    {groups} [groups]:group+;

  group =
    [name]:identifier [tokens]:token+;

  token =
    {simple}    [name]:identifier regular_expression three_dots? |
    {selection} selection selector regular_expression three_dots?;

  selection =
    [names]:identifier+;

  selector =
    [name]:identifier;

  priorities =
    [priorities]:priority+;

  priority =
    [high_tokens]:token_collection [low_tokens]:token_collection;

  investigators =
    [investigators]:investigator+;

  investigator =
    token_collection [name]:identifier;

  states =
    [normal_states]:normal_state+ internal_states?;

  normal_state =
    [name]:identifier token_collection priorities? ignored? lookahead?;

  lookahead =
    {none}     |
    {infinite} ;

  ignored =
    [identifiers]:identifier+;

  internal_states =
    [internal_states]:internal_state+ transitions?;

  internal_state =
    [name]:identifier token_collection priorities? lookahead?;

  transitions =
    [transitions]:transition+;

  transition =
    {normal} [source]:identifier token_collection [destination]:identifier|
    {back}   [source]:identifier token_collection;

  regular_expression =
    {union}         [left_regular_expression]:regular_expression [right_regular_expression]:regular_expression |
    {subtraction}   [left_regular_expression]:regular_expression [right_regular_expression]:regular_expression |
    {concatenation} [left_regular_expression]:regular_expression [right_regular_expression]:regular_expression |
    {zero_or_one}   regular_expression |
    {zero_or_more}  regular_expression |
    {one_or_more}   regular_expression |
    {intersection}  [left_regular_expression]:regular_expression [right_regular_expression]:regular_expression |
    {shortest}      regular_expression |
    {interval}      [lower_bound]:character [upper_bound]:character |
    {string}        string |
    {character}     character |
    {empty_string}  |
    {helper}        identifier;

  character =
    {character}   character_token |
    {decimal}     decimal_number |
    {hexadecimal} hexadecimal_number;

  token_collection =
    {complete}  |
    {inclusive} [identifiers]:identifier+ |
    {exclusive} [identifiers]:identifier+;
