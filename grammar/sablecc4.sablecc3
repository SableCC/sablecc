/* This file is part of SableCC ( http://sablecc.org ).
 *
 * See the NOTICE file distributed with this work for copyright information.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

Package org.sablecc.sablecc.syntax3;

Helpers

  any = [0 .. 0xffff];

  carriage_return = 13;
  line_feed       = 10;
  tab             = 9;
  white_space     = ' ';

  end_of_line     =
    carriage_return |
    line_feed |
    carriage_return line_feed;

  decimal_digit     = ['0' .. '9'];
  hexadecimal_digit = [decimal_digit + ['a' .. 'f']];
  lower_case_letter = ['a' .. 'z'];
  upper_case_letter = ['A' .. 'Z'];

  string_character  = [[32..126] - '''];

  identifier_part = lower_case_letter (lower_case_letter | decimal_digit)*;

  not_star       = [any - '*'];
  not_star_slash = [any - ['/' + '*']];

  not_end_of_line = [any - [carriage_return + line_feed]];

Tokens

  // keywords

  all_keyword           = 'All';
  any_keyword           = 'Any';
  back_keyword          = 'Back';
  except_keyword        = 'Except';
  group_keyword         = 'Group';
  helpers_keyword       = 'Helpers';
  ignored_keyword       = 'Ignored';
  infinite_keyword      = 'Infinite';
  internal_keyword      = 'Internal';
  intersection_keyword  = 'Intersection';
  investigators_keyword = 'Investigators';
  language_keyword      = 'Language';
  lookahead_keyword     = 'Lookahead';
  lexer_keyword         = 'Lexer';
  none_keyword          = 'None';
  over_keyword          = 'Over';
  priorities_keyword    = 'Priorities';
  shortest_keyword      = 'Shortest';
  state_keyword         = 'State';
  states_keyword        = 'States';
  syntax_keyword        = 'Syntax';
  tokens_keyword        = 'Tokens';
  transitions_keyword   = 'Transitions';

  // separators

  arrow      = '->';
  colon      = ':';
  comma      = ',';
  semicolon  = ';';
  three_dots = '...';
  two_dots   = '..';

  left_parenthesis  = '(';
  right_parenthesis = ')';

  // operators

  assign        = '=';
  bar           = '|';
  caret         = '^';
  minus         = '-';
  plus          = '+';
  question_mark = '?';
  star          = '*';

  // identifier, numbers, strings and character

  identifier = identifier_part ('_' identifier_part)*;

  erroneous_identifier =
    (lower_case_letter | upper_case_letter | '_') (lower_case_letter | upper_case_letter | '_' | decimal_digit)*;

  number = decimal_digit+;

  decimal_character     = '#' decimal_digit+;
  hexadecimal_character = '#' 'x' hexadecimal_digit+;

  empty_string    = ''' ''';
  character_token = ''' (string_character | ''') ''';
  string          = ''' string_character string_character+ ''';

  // comments (will change once sablecc 4 generates its own front-end)

  long_comment = '/*' not_star* ('*' (not_star_slash not_star*)?)* '*/';
  line_comment = '//' not_end_of_line* end_of_line?;

  // blanks

  blanks = (white_space | tab | end_of_line)+;

Ignored Tokens

  blanks, long_comment, line_comment;

Productions

  // specification

  specification =
    header lexer  {-> New specification(header, lexer) };

  // header

  header =
    language syntax  {-> New header(language, syntax) };

  language =
    language_keyword [name]:identifier semicolon  {-> New language(name) };

  syntax =
    syntax_keyword [version]:number semicolon  {-> New syntax(version) };

  // lexer

  lexer =
    {no_states} lexer_keyword helpers? tokens investigators? priorities? ignored? lookahead?  {-> New lexer.no_states(helpers, tokens, investigators, priorities, ignored, lookahead) } |
    {states}    lexer_keyword helpers? tokens investigators? states  {-> New lexer.states(helpers, tokens, investigators, states) };

  // helpers

  helpers =
    helpers_keyword [helpers]:helper+  {-> New helpers([helpers]) };

  helper =
    [name]:identifier assign regular_expression semicolon  {-> New helper(name, regular_expression) };

  // tokens

  tokens =
    {simple} tokens_keyword [tokens]:token+  {-> New tokens.simple([tokens]) } |
    {groups} tokens_keyword [groups]:group+  {-> New tokens.groups([groups]) };

  group =
    group_keyword [name]:identifier colon [tokens]:token+  {-> New group(name, [tokens]) };

  token =
    {simple}    [name]:identifier assign regular_expression three_dots? semicolon  {-> New token.simple(name, regular_expression, three_dots) } |
    {selection} selection colon selector assign regular_expression three_dots? semicolon  {-> New token.selection(selection, selector, regular_expression, three_dots) };

  selection =
    identifier_list  {-> New selection([identifier_list.identifiers]) };

  selector =
    [name]:identifier left_parenthesis right_parenthesis  {-> New selector(name) };

  // priorities

  priorities =
    priorities_keyword [priorities]:priority+  {-> New priorities([priorities]) };

  priority =
    [high_priority_tokens]:token_collection over_keyword [low_priority_tokens]:token_collection semicolon  {-> New priority(high_priority_tokens, low_priority_tokens) };

  // investigators

  investigators =
    investigators_keyword [investigators]:investigator+  {-> New investigators([investigators]) };

  investigator =
    token_collection colon [name]:identifier left_parenthesis right_parenthesis semicolon  {-> New investigator(token_collection, name) };

  // states

  states =
    states_keyword [normal_states]:normal_state+ internal_states?  {-> New states([normal_states], internal_states) };

  normal_state =
    state_keyword [name]:identifier colon tokens_keyword token_collection semicolon priorities? ignored? lookahead?  {-> New normal_state(name, token_collection, priorities, ignored, lookahead) };

  lookahead =
    {none}     lookahead_keyword none_keyword semicolon  {-> New lookahead.none() } |
    {infinite} lookahead_keyword infinite_keyword semicolon  {-> New lookahead.infinite() };

  ignored =
    ignored_keyword token_collection semicolon  {-> New ignored(token_collection) };

  internal_states =
    internal_keyword [internal_states]:internal_state+ transitions?  {-> New internal_states([internal_states], transitions) };

  internal_state =
    state_keyword [name]:identifier colon tokens_keyword token_collection semicolon priorities? lookahead?  {-> New internal_state(name, token_collection, priorities, lookahead) };

  transitions =
    transitions_keyword [transitions]:transition+  {-> New transitions([transitions]) };

  transition =
    {normal} [source]:identifier [tail_arrow]:arrow left_parenthesis token_collection right_parenthesis [head_arrow]:arrow [destination]:identifier semicolon  {-> New transition.normal(source, token_collection, destination) } |
    {back}   [source]:identifier [tail_arrow]:arrow left_parenthesis token_collection right_parenthesis [head_arrow]:arrow back_keyword semicolon  {-> New transition.back(source, token_collection) };

  // regular expression

  regular_expression =
    {simple}         sub_expression  {-> sub_expression.regular_expression } |
    {interval}       interval  {-> interval.regular_expression } |
    {sub_union}      regular_expression bar sub_expression  {-> New regular_expression.union(regular_expression, sub_expression.regular_expression) } |
    {interval_union} regular_expression bar interval  {-> New regular_expression.union(regular_expression, interval.regular_expression) };

  interval  {-> regular_expression } =
    [lower_bound]:character two_dots [upper_bound]:character  {-> New regular_expression.interval(lower_bound, upper_bound) };

  sub_expression  {-> regular_expression } =
    {simple}      factor  {-> factor.regular_expression } |
    {subtraction} sub_expression minus factor  {-> New regular_expression.subtraction(sub_expression.regular_expression, factor.regular_expression) };

  factor  {-> regular_expression } =
    {simple}        unary_expression  {-> unary_expression.regular_expression } |
    {concatenation} factor unary_expression  {-> New regular_expression.concatenation(factor.regular_expression, unary_expression.regular_expression) };

  unary_expression  {-> regular_expression } =
    {simple}       term  {-> term.regular_expression } |
    {zero_or_one}  term question_mark  {-> New regular_expression.zero_or_one(term.regular_expression) } |
    {zero_or_more} term star  {-> New regular_expression.zero_or_more(term.regular_expression) } |
    {one_or_more}  term plus  {-> New regular_expression.one_or_more(term.regular_expression) } |
    {exponent}     term caret [times]:number  {-> New regular_expression.exponent(term.regular_expression, times) } |
    {range}        term caret left_parenthesis [from]:number two_dots [to]:number right_parenthesis  {-> New regular_expression.range(term.regular_expression, from, to) } |
    {at_least}     term caret left_parenthesis [times]:number three_dots right_parenthesis  {-> New regular_expression.at_least(term.regular_expression, times) } ;

  term  {-> regular_expression } =
    {intersection}  intersection_keyword left_parenthesis [left_regular_expression]:regular_expression comma [right_regular_expression]:regular_expression right_parenthesis  {-> New regular_expression.intersection(left_regular_expression, right_regular_expression) } |
    {shortest}      shortest_keyword left_parenthesis regular_expression right_parenthesis  {-> New regular_expression.shortest(regular_expression) } |
    {parenthesized} left_parenthesis regular_expression right_parenthesis  {-> regular_expression } |
    {string}        string  {-> New regular_expression.string(string) } |
    {character}     character  {-> New regular_expression.character(character) } |
    {any}           any_keyword  {-> New regular_expression.any() } |
    {empty_string}  empty_string  {-> New regular_expression.empty_string() } |
    {helper}        identifier  {-> New regular_expression.helper(identifier) };

  character =
    {character}   character_token |
    {decimal}     decimal_character |
    {hexadecimal} hexadecimal_character;

  // token collection

  token_collection =
    {complete}  all_keyword  {-> New token_collection.complete() } |
    {inclusive} identifier_list  {-> New token_collection.inclusive([identifier_list.identifiers]) } |
    {exclusive} all_keyword except_keyword identifier_list  {-> New token_collection.exclusive([identifier_list.identifiers]) } |
    {subset}    identifier_list except_keyword [excluded_identifiers]:identifier_list  {-> New token_collection.subset([identifier_list.identifiers], [excluded_identifiers.identifiers]) };

  // identifier list

  identifier_list  {-> [identifiers]:identifier+ } =
    identifier [additional_identifiers]:additional_identifier*  {-> [identifier, additional_identifiers.identifier] };

  additional_identifier  {-> identifier } =
    comma identifier  {-> identifier};

Abstract Syntax Tree

  specification =
    header lexer;

  header =
    language syntax;

  language =
    [name]:identifier;

  syntax =
    [version]:number;

  lexer =
    {no_states} helpers? tokens investigators? priorities? ignored? lookahead? |
    {states}    helpers? tokens investigators? states;

  helpers =
    [helpers]:helper+;

  helper =
    [name]:identifier regular_expression;

  tokens =
    {simple} [tokens]:token+ |
    {groups} [groups]:group+;

  group =
    [name]:identifier [tokens]:token+;

  token =
    {simple}    [name]:identifier regular_expression three_dots? |
    {selection} selection selector regular_expression three_dots?;

  selection =
    [names]:identifier+;

  selector =
    [name]:identifier;

  priorities =
    [priorities]:priority+;

  priority =
    [high_priority_tokens]:token_collection [low_priority_tokens]:token_collection;

  investigators =
    [investigators]:investigator+;

  investigator =
    token_collection [name]:identifier;

  states =
    [normal_states]:normal_state+ internal_states?;

  normal_state =
    [name]:identifier token_collection priorities? ignored? lookahead?;

  lookahead =
    {none}     |
    {infinite} ;

  ignored =
    token_collection;

  internal_states =
    [internal_states]:internal_state+ transitions?;

  internal_state =
    [name]:identifier token_collection priorities? lookahead?;

  transitions =
    [transitions]:transition+;

  transition =
    {normal} [source]:identifier token_collection [destination]:identifier|
    {back}   [source]:identifier token_collection;

  regular_expression =
    {union}         [left_regular_expression]:regular_expression [right_regular_expression]:regular_expression |
    {subtraction}   [left_regular_expression]:regular_expression [right_regular_expression]:regular_expression |
    {concatenation} [left_regular_expression]:regular_expression [right_regular_expression]:regular_expression |
    {zero_or_one}   regular_expression |
    {zero_or_more}  regular_expression |
    {one_or_more}   regular_expression |
    {exponent}      regular_expression [times]:number |
    {range}         regular_expression [from]:number [to]:number|
    {at_least}      regular_expression [times]:number|
    {intersection}  [left_regular_expression]:regular_expression [right_regular_expression]:regular_expression |
    {shortest}      regular_expression |
    {interval}      [lower_bound]:character [upper_bound]:character |
    {string}        string |
    {character}     character |
    {any}           |
    {empty_string}  |
    {helper}        identifier;

  character =
    {character}   character_token |
    {decimal}     decimal_character |
    {hexadecimal} hexadecimal_character;

  token_collection =
    {complete}  |
    {inclusive} [identifiers]:identifier+ |
    {exclusive} [identifiers]:identifier+ |
    {subset}    [identifiers]:identifier+ [excluded_identifiers]:identifier+;
